ğŸ“˜ COURS : Normalisation dâ€™une Matrice de Confusion

ğŸ¯ Objectif

Comprendre comment interprÃ©ter correctement une matrice de confusion suivant le type de normalisation choisi, et quel KPI chaque mÃ©thode met en lumiÃ¨re.

â¸»

1ï¸âƒ£ Rappel : Matrice de Confusion

Une matrice de confusion est un tableau qui rÃ©sume les performances dâ€™un modÃ¨le de classification.

	PrÃ©dits = Chat	PrÃ©dits = Chien	PrÃ©dits = Lapin
Vrais Chats	TP	FP (Chat â†’ Chien)	FP
Vrais Chiens	FN (Chien â†’ Chat)	TP	FP
Vrais Lapins	FN	FN	TP

ğŸ‘‰ La diagonale reprÃ©sente les bonnes prÃ©dictions (True Positive).
ğŸ‘‰ Hors diagonale = erreurs de classification (confusions).

â¸»

2ï¸âƒ£ Pourquoi normaliser ?

Sans normalisation â†’ risques dâ€™erreurs dâ€™interprÃ©tation ğŸš¨

Si une classe a beaucoup plus dâ€™exemples, elle dominera la matrice.

Exemple :
	â€¢	Classe A : 10 000 exemples
	â€¢	Classe B : 30 exemples

â¡ï¸ Sans normalisation, les erreurs de B seront invisibles ğŸ˜¨
â¡ï¸ La normalisation permet de ramener les classes Ã  la mÃªme Ã©chelle.

â¸»

3ï¸âƒ£ Les 4 normalisations standard (scikit-learn)

ğŸ“Œ 1. Aucune normalisation
	â€¢	Valeurs brutes
	â€¢	On observe les volumes rÃ©els
	â€¢	Utile pour dÃ©tecter les dÃ©sÃ©quilibres de classes

â¸»

ğŸ“Œ 2. Normalisation par ligne (row)

Division par : total des vrais exemples (ligne)

CM_{norm}(i,j) = \frac{CM(i,j)}{\sum_j CM(i,j)}

â¡ï¸ Chaque ligne = 100% des vrais X

Cette normalisation calcule en fait le Recall / SensibilitÃ© par classe.

InterprÃ©tation

Parmi tous les vrais X, combien sont bien ou mal prÃ©dits ?

â¸»

ğŸ“Œ 3. Normalisation par colonne (pred)

Division par : total des prÃ©dictions de la classe (colonne)

CM_{norm}(i,j) = \frac{CM(i,j)}{\sum_i CM(i,j)}

â¡ï¸ Chaque colonne = 100% des prÃ©dictions Y

Cette normalisation mesure la PrÃ©cision par classe.

InterprÃ©tation

Quand le modÃ¨le prÃ©dit Y, est-il fiable ?

â¸»

ğŸ“Œ 4. Normalisation globale (all)

Division par : total des observations

Tout devient des pourcentages globaux.

InterprÃ©tation

Quelle proportion du dataset total se trouve dans chaque case ?

âœ”ï¸ Simple, bonne vue dâ€™ensemble
âŒ Peut masquer les erreurs de petites classes

â¸»

4ï¸âƒ£ â­ MÃ©thode BONUS (non standard)

âœ¨ Normalisation diagonale (ta demande)

Cette mÃ©thode divise chaque ligne par la valeur diagonale de la classe (TP).

CM_{norm}(i,j) = \frac{CM(i,j)}{CM(i,i)}

ğŸ“Œ Objectif : comprendre lâ€™importance des erreurs par rapport aux rÃ©ussites

InterprÃ©tation

Pour 1 bonne prÃ©diction, combien dâ€™erreurs ?
Quel type de confusion est le plus dangereux ?

â¸»

5ï¸âƒ£ ğŸ§  Lien avec les mÃ©triques classiques

Normalisation	KPI Ã©quivalent
Ligne (row)	Recall
Colonne (pred)	PrÃ©cision
Globale (all)	Accuracy (vue mÃ©langÃ©e)
Aucune	Comptage brut
Diagonale	Poids des erreurs / SuccÃ¨s (non standard)


â¸»

6ï¸âƒ£ ğŸ“Š Tableau comparatif demandÃ©

MÃ©thode de normalisation	Division par	KPI mesurÃ©	InterprÃ©tation	Quand lâ€™utiliser
Aucune (valeurs brutes)	rien	â€”	volume rÃ©el des erreurs / succÃ¨s	Diagnostiquer le dÃ©sÃ©quilibre de classes, comprendre les quantitÃ©s
Ligne (row) âœ”ï¸ ta mÃ©thode actuelle	total de la classe rÃ©elle (somme ligne)	Recall / SensibilitÃ©	Parmi tous les vrais X, combien bien/mal prÃ©dits ?	Dataset dÃ©sÃ©quilibrÃ©, Ã©valuer qualitÃ© par classe
Colonne (pred)	total des prÃ©dictions de la colonne	PrÃ©cision	Quand je prÃ©dis Y, suis-je fiable ?	Ã‰viter les faux positifs, dÃ©cisions sensibles (mÃ©decine, assurance fraude, sÃ©curitÃ©)
Globale (all)	total global	% du dataset	Vue dâ€™ensemble de la performance	Communication simple, rapport exÃ©cutif / board
Diagonale ğŸ”¥ non standard	vrai positif (Ã©lÃ©ment diagonal)	Erreur relative au succÃ¨s	Par rapport au bon classement, combien dâ€™erreurs ?	Comprendre les confusions principales, tuning, diagnostic fin


â¸»

7ï¸âƒ£ ğŸ RÃ©sumÃ© Ã  retenir absolument

Si tu veux Ã©valuerâ€¦	Alors utiliseâ€¦
La qualitÃ© par classe	Normalisation ligne
La fiabilitÃ© des prÃ©dictions	Normalisation colonne
La performance globale	Normalisation globale
Le volume rÃ©el	Aucune
Les erreurs critiques par rapport aux succÃ¨s	Diagonale


â¸»

ğŸ‰ Conclusion finale

La normalisation dâ€™une matrice de confusion change lâ€™angle dâ€™analyse :

ğŸ“Œ On ne change pas les donnÃ©es, on change la faÃ§on de les lire.

ğŸ‘‰ Câ€™est un outil stratÃ©gique pour comprendre un modÃ¨le,
ğŸ‘‰ surtout dans des contextes professionnels Ã  fort enjeu (banque, assurance, santÃ©, fraude, industrie).

â¸»