{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc692587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-25 17:33:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mconfig.py:67\u001b[0m | \u001b[33mconfigure_logging()\u001b[0m | Loguru configuré avec succès (mode: dev) | {'env': 'dev'}\n",
      "\u001b[32m2025-12-25 17:33:49\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmlflow_setup.py:36\u001b[0m | \u001b[33m__init__()\u001b[0m | Tracking URI : sqlite://///Users/surelmanda/Downloads/ml-projects/mlflow_central/db/mlruns.db | {}\n",
      "\u001b[32m2025-12-25 17:33:49\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmlflow_setup.py:37\u001b[0m | \u001b[33m__init__()\u001b[0m | Artifact URI : /Users/surelmanda/Downloads/ml-projects/mlflow_central/mlflow_artifacts | {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 17:33:50 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/12/25 17:33:50 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025/12/25 17:33:50 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/25 17:33:50 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2025/12/25 17:33:50 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/25 17:33:50 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-25 17:33:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_setup.py:53\u001b[0m | \u001b[33mconfigure()\u001b[0m | MLflow configuré avec succès. | {}\n",
      "Starting experiment 'health_lifestyle_diabetes' with run name 'Catb_2025-12-25_17h33m50s'\n",
      "\u001b[32m2025-12-25 17:33:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_tracker.py:25\u001b[0m | \u001b[33m__init__()\u001b[0m | MLflowExperimentTracker prêt. | {}\n",
      "\u001b[32m2025-12-25 17:33:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mexperiment_tracking_service.py:23\u001b[0m | \u001b[33m__init__()\u001b[0m | ExperimentTrackingService initialisé. | {}\n",
      "\u001b[32m2025-12-25 17:33:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mexperiment_tracking_service.py:30\u001b[0m | \u001b[33mstart_experiment()\u001b[0m | Initialisation de l'expérience 'health_lifestyle_diabetes' (run='Catb_2025-12-25_17h33m50s') | {}\n",
      "\u001b[32m2025-12-25 17:33:50\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mmlflow_tracker.py:40\u001b[0m | \u001b[33msetup_experiment()\u001b[0m | Expérience supprimée détectée. Restauration en cours. | {}\n",
      "\u001b[32m2025-12-25 17:33:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_tracker.py:56\u001b[0m | \u001b[33msetup_experiment()\u001b[0m | Expérience active : health_lifestyle_diabetes | {}\n",
      "\u001b[32m2025-12-25 17:33:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_tracker.py:70\u001b[0m | \u001b[33mstart_run()\u001b[0m | Run démarrée : Catb_2025-12-25_17h33m50s | {}\n",
      "\u001b[32m2025-12-25 17:33:50\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mexperiment_tracking_service.py:43\u001b[0m | \u001b[33mlog_training_context()\u001b[0m | Enregistrement du contexte d'entraînement pour XGBoostClassifier | {}\n",
      "\u001b[32m2025-12-25 17:33:50\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmlflow_tracker.py:83\u001b[0m | \u001b[33mlog_params()\u001b[0m | Paramètres enregistrés : {'model': 'XGBoostClassifier', 'max_depth': 6, 'learning_rate': 0.05, 'n_estimators': 300, 'subsample': 0.8} | {}\n",
      "\u001b[32m2025-12-25 17:33:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mexperiment_tracking_service.py:48\u001b[0m | \u001b[33mlog_evaluation()\u001b[0m | Métriques d'évaluation : {'auc': 0.723, 'accuracy': 0.806, 'balanced_accuracy': 0.845, 'precision': 0.659, 'recall': 0.748, 'f1_score': 0.701, 'log_loss': 0.509, 'error_rate': 0.194} | {}\n",
      "\u001b[32m2025-12-25 17:33:50\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmlflow_tracker.py:87\u001b[0m | \u001b[33mlog_metrics()\u001b[0m | Métriques enregistrées : {'auc': 0.723, 'accuracy': 0.806, 'balanced_accuracy': 0.845, 'precision': 0.659, 'recall': 0.748, 'f1_score': 0.701, 'log_loss': 0.509, 'error_rate': 0.194} | {}\n",
      "\u001b[32m2025-12-25 17:33:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mexperiment_tracking_service.py:61\u001b[0m | \u001b[33mclose()\u001b[0m | Fermeture de l'expérience. | {}\n",
      "\u001b[32m2025-12-25 17:33:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_tracker.py:76\u001b[0m | \u001b[33mend_run()\u001b[0m | Fermeture de la run : 1800010da5d440c6bbfa93bd10bcd8e1 | {}\n"
     ]
    }
   ],
   "source": [
    "from health_lifestyle_diabetes.infrastructure.logger.config import configure_logging\n",
    "from health_lifestyle_diabetes.infrastructure.logger.loguru_logger import LoguruLogger\n",
    "from health_lifestyle_diabetes.infrastructure.tracking.mlflow_tracker import MLflowExperimentTracker\n",
    "from health_lifestyle_diabetes.application.services.experiment_tracking_service import ExperimentTrackingService\n",
    "from health_lifestyle_diabetes.infrastructure.tracking.run_name_generator import generate_run_name\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# 1) Fonction pour simuler des métriques d'entraînement\n",
    "def simulate_training_metrics() -> dict:\n",
    "    \"\"\"\n",
    "    Simulate model evaluation metrics for a binary classification task.\n",
    "    \"\"\"\n",
    "    auc = round(random.uniform(0.70, 0.90), 3)\n",
    "    precision = round(random.uniform(0.65, 0.90), 3)\n",
    "    recall = round(random.uniform(0.60, 0.88), 3)\n",
    "\n",
    "    f1_score = round(\n",
    "        2 * precision * recall / (precision + recall + 1e-8), 3\n",
    "    )\n",
    "\n",
    "    accuracy = round(random.uniform(0.70, 0.88), 3)\n",
    "    balanced_accuracy = round(random.uniform(0.68, 0.86), 3)\n",
    "    log_loss = round(random.uniform(0.35, 0.65), 3)\n",
    "\n",
    "    error_rate = round(1 - accuracy, 3)\n",
    "\n",
    "    return {\n",
    "        \"auc\": auc,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"balanced_accuracy\": balanced_accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"log_loss\": log_loss,\n",
    "        \"error_rate\": error_rate,\n",
    "    }\n",
    "\n",
    "# 2) Configuration du logging global\n",
    "configure_logging(env=\"dev\")\n",
    "\n",
    "# 3) Injection des dépendances\n",
    "logger = LoguruLogger()\n",
    "ml_tracker = MLflowExperimentTracker(logger=logger)\n",
    "tracking = ExperimentTrackingService(tracker=ml_tracker, logger=logger)\n",
    "\n",
    "# 4) Démarrage de l'expérience\n",
    "EXPERIMENT_NAME = \"health_lifestyle_diabetes\"\n",
    "PREFIX_NAME = \"Catb\"\n",
    "MODEL_NAME = generate_run_name(prefix=PREFIX_NAME)\n",
    "\n",
    "print(f\"Starting experiment '{EXPERIMENT_NAME}' with run name '{MODEL_NAME}'\")\n",
    "\n",
    "tracking.start_experiment(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    run_name=MODEL_NAME\n",
    ")\n",
    "\n",
    "# 5) Exemple de paramètres du modèle\n",
    "params = {\n",
    "    \"max_depth\": 6,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"n_estimators\": 300,\n",
    "    \"subsample\": 0.8\n",
    "}\n",
    "tracking.log_training_context(model_name=\"XGBoostClassifier\", params=params)\n",
    "\n",
    "# 6) Exemple de métriques post-entraînement\n",
    "# Simulate training => Model training simulation started\n",
    "metrics = simulate_training_metrics()\n",
    "tracking.log_evaluation(metrics)\n",
    "\n",
    "# 7) Exemple d'artefact (simulation d'un fichier de modèle)\n",
    "#model_path = \"models/xgb_baseline.pkl\"\n",
    "#with open(model_path, \"w\") as f:\n",
    "#    f.write(\"simulated binary content of a ML model\")\n",
    "#tracking.log_artifact(model_path)\n",
    "\n",
    "# 8) Clôture propre de la run\n",
    "tracking.close()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# RÉSULTAT ATTENDU\n",
    "# -----------------------------\n",
    "# - Une expérience \"diabetes_prediction\" est visible dans MLflow\n",
    "# - Une run \"baseline_xgboost\" est enregistrée\n",
    "# - Les paramètres, métriques et artefacts sont disponibles dans l'UI MLflow\n",
    "# \n",
    "# Pour lancer l'interface MLflow :\n",
    "#     poetry run mlflow ui\n",
    "# Puis ouvrir http://localhost:5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087a4403",
   "metadata": {},
   "source": [
    "# CatBoost + MLflow (Clean Architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879515d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-25 17:56:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mconfig.py:67\u001b[0m | \u001b[33mconfigure_logging()\u001b[0m | Loguru configuré avec succès (mode: dev) | {'env': 'dev'}\n",
      "\u001b[32m2025-12-25 17:56:39\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmlflow_setup.py:36\u001b[0m | \u001b[33m__init__()\u001b[0m | Tracking URI : sqlite://///Users/surelmanda/Downloads/ml-projects/mlflow_central/db/mlruns.db | {}\n",
      "\u001b[32m2025-12-25 17:56:39\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmlflow_setup.py:37\u001b[0m | \u001b[33m__init__()\u001b[0m | Artifact URI : /Users/surelmanda/Downloads/ml-projects/mlflow_central/mlflow_artifacts | {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 17:56:40 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/12/25 17:56:40 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025/12/25 17:56:40 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/25 17:56:40 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2025/12/25 17:56:40 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/25 17:56:40 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-25 17:56:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_setup.py:53\u001b[0m | \u001b[33mconfigure()\u001b[0m | MLflow configuré avec succès. | {}\n",
      "\u001b[32m2025-12-25 17:56:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_tracker.py:25\u001b[0m | \u001b[33m__init__()\u001b[0m | MLflowExperimentTracker prêt. | {}\n",
      "\u001b[32m2025-12-25 17:56:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mexperiment_tracking_service.py:23\u001b[0m | \u001b[33m__init__()\u001b[0m | ExperimentTrackingService initialisé. | {}\n",
      "\u001b[32m2025-12-25 17:56:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mexperiment_tracking_service.py:30\u001b[0m | \u001b[33mstart_experiment()\u001b[0m | Initialisation de l'expérience 'health_lifestyle_diabetes' (run='CATB_2025-12-25_17h56m40s') | {}\n",
      "\u001b[32m2025-12-25 17:56:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_tracker.py:56\u001b[0m | \u001b[33msetup_experiment()\u001b[0m | Expérience active : health_lifestyle_diabetes | {}\n",
      "\u001b[32m2025-12-25 17:56:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_tracker.py:70\u001b[0m | \u001b[33mstart_run()\u001b[0m | Run démarrée : CATB_2025-12-25_17h56m40s | {}\n",
      "\u001b[32m2025-12-25 17:56:40\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mexperiment_tracking_service.py:43\u001b[0m | \u001b[33mlog_training_context()\u001b[0m | Enregistrement du contexte d'entraînement pour CatBoostClassifier | {}\n",
      "\u001b[32m2025-12-25 17:56:40\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmlflow_tracker.py:83\u001b[0m | \u001b[33mlog_params()\u001b[0m | Paramètres enregistrés : {'model': 'CatBoostClassifier', 'iterations': 300, 'learning_rate': 0.05, 'depth': 6, 'loss_function': 'Logloss', 'eval_metric': 'AUC'} | {}\n",
      "\u001b[32m2025-12-25 17:56:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mexperiment_tracking_service.py:48\u001b[0m | \u001b[33mlog_evaluation()\u001b[0m | Métriques d'évaluation : {'accuracy': 0.956140350877193, 'f1_score': 0.9659863945578231, 'auc': 0.9940476190476191} | {}\n",
      "\u001b[32m2025-12-25 17:56:41\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmlflow_tracker.py:87\u001b[0m | \u001b[33mlog_metrics()\u001b[0m | Métriques enregistrées : {'accuracy': 0.956140350877193, 'f1_score': 0.9659863945578231, 'auc': 0.9940476190476191} | {}\n",
      "\u001b[32m2025-12-25 17:56:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mexperiment_tracking_service.py:61\u001b[0m | \u001b[33mclose()\u001b[0m | Fermeture de l'expérience. | {}\n",
      "\u001b[32m2025-12-25 17:56:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_tracker.py:76\u001b[0m | \u001b[33mend_run()\u001b[0m | Fermeture de la run : 84dac8f44a3e449ea5c3e61f7929e0ba | {}\n",
      "\n",
      "Exécution terminée. Vérifier MLflow UI.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0) Imports - Dépendances Clean Architecture\n",
    "# ============================================================\n",
    "from health_lifestyle_diabetes.infrastructure.logger.config import configure_logging\n",
    "from health_lifestyle_diabetes.infrastructure.logger.loguru_logger import LoguruLogger\n",
    "from health_lifestyle_diabetes.infrastructure.tracking.mlflow_tracker import MLflowExperimentTracker\n",
    "from health_lifestyle_diabetes.application.services.experiment_tracking_service import ExperimentTrackingService\n",
    "from health_lifestyle_diabetes.infrastructure.tracking.run_name_generator import generate_run_name\n",
    "\n",
    "# ============================================================\n",
    "# 1) Dataset (réel) - Breast Cancer\n",
    "# ============================================================\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Charger le dataset\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 2) Config log + injection dépendances\n",
    "# ============================================================\n",
    "configure_logging(env=\"dev\")\n",
    "\n",
    "logger = LoguruLogger()\n",
    "tracker = MLflowExperimentTracker(logger)\n",
    "tracking = ExperimentTrackingService(tracker=tracker, logger=logger)\n",
    "\n",
    "# ============================================================\n",
    "# 3) Démarrer une expérience CatBoost dans MLflow\n",
    "# ============================================================\n",
    "EXPERIMENT_NAME = \"health_lifestyle_diabetes\"\n",
    "RUN_NAME = generate_run_name(prefix=\"CATB\")\n",
    "print(f\"Starting experiment '{EXPERIMENT_NAME}' with run name '{MODEL_NAME}'\")\n",
    "\n",
    "\n",
    "tracking.start_experiment(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    run_name=RUN_NAME\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 4) Définition du modèle + log des paramètres\n",
    "# ============================================================\n",
    "model_params = {\n",
    "    \"iterations\": 300,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"depth\": 6,\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"AUC\"\n",
    "}\n",
    "\n",
    "model = CatBoostClassifier(**model_params, verbose=False)\n",
    "\n",
    "tracking.log_training_context(\n",
    "    model_name=\"CatBoostClassifier\",\n",
    "    params=model_params\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 5) Entraînement réel\n",
    "# ============================================================\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ============================================================\n",
    "# 6) Évaluation\n",
    "# ============================================================\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"f1_score\": f1_score(y_test, y_pred),\n",
    "    \"auc\": roc_auc_score(y_test, y_proba)\n",
    "}\n",
    "\n",
    "tracking.log_evaluation(metrics)\n",
    "\n",
    "# ============================================================\n",
    "# 7) Sauvegarde modèle en artefact\n",
    "# ============================================================\n",
    "#model_path = f\"models/{RUN_NAME}.cbm\"\n",
    "#model.save_model(model_path)\n",
    "#tracking.log_artifact(model_path)\n",
    "\n",
    "# ============================================================\n",
    "# 8) Fin de l'expérience\n",
    "# ============================================================\n",
    "tracking.close()\n",
    "\n",
    "print(\"\\nExécution terminée. Vérifier MLflow UI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6103b",
   "metadata": {},
   "source": [
    "# XGBoost + MLflow (Clean Architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b17e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-25 17:57:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mconfig.py:67\u001b[0m | \u001b[33mconfigure_logging()\u001b[0m | Loguru configuré avec succès (mode: dev) | {'env': 'dev'}\n",
      "\u001b[32m2025-12-25 17:57:50\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmlflow_setup.py:36\u001b[0m | \u001b[33m__init__()\u001b[0m | Tracking URI : sqlite://///Users/surelmanda/Downloads/ml-projects/mlflow_central/db/mlruns.db | {}\n",
      "\u001b[32m2025-12-25 17:57:50\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmlflow_setup.py:37\u001b[0m | \u001b[33m__init__()\u001b[0m | Artifact URI : /Users/surelmanda/Downloads/ml-projects/mlflow_central/mlflow_artifacts | {}\n",
      "\u001b[32m2025-12-25 17:57:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_setup.py:53\u001b[0m | \u001b[33mconfigure()\u001b[0m | MLflow configuré avec succès. | {}\n",
      "\u001b[32m2025-12-25 17:57:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_tracker.py:25\u001b[0m | \u001b[33m__init__()\u001b[0m | MLflowExperimentTracker prêt. | {}\n",
      "\u001b[32m2025-12-25 17:57:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mexperiment_tracking_service.py:23\u001b[0m | \u001b[33m__init__()\u001b[0m | ExperimentTrackingService initialisé. | {}\n",
      "\u001b[32m2025-12-25 17:57:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mexperiment_tracking_service.py:30\u001b[0m | \u001b[33mstart_experiment()\u001b[0m | Initialisation de l'expérience 'health_lifestyle_diabetes' (run='XGB_2025-12-25_17h57m50s') | {}\n",
      "\u001b[32m2025-12-25 17:57:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_tracker.py:56\u001b[0m | \u001b[33msetup_experiment()\u001b[0m | Expérience active : health_lifestyle_diabetes | {}\n",
      "\u001b[32m2025-12-25 17:57:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_tracker.py:70\u001b[0m | \u001b[33mstart_run()\u001b[0m | Run démarrée : XGB_2025-12-25_17h57m50s | {}\n",
      "\u001b[32m2025-12-25 17:57:50\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mexperiment_tracking_service.py:43\u001b[0m | \u001b[33mlog_training_context()\u001b[0m | Enregistrement du contexte d'entraînement pour XGBClassifier | {}\n",
      "\u001b[32m2025-12-25 17:57:50\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmlflow_tracker.py:83\u001b[0m | \u001b[33mlog_params()\u001b[0m | Paramètres enregistrés : {'model': 'XGBClassifier', 'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'eval_metric': 'logloss'} | {}\n",
      "\u001b[32m2025-12-25 17:57:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mexperiment_tracking_service.py:48\u001b[0m | \u001b[33mlog_evaluation()\u001b[0m | Métriques d'évaluation : {'accuracy': 0.9649122807017544, 'f1_score': 0.9726027397260274, 'auc': 0.9957010582010581} | {}\n",
      "\u001b[32m2025-12-25 17:57:50\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmlflow_tracker.py:87\u001b[0m | \u001b[33mlog_metrics()\u001b[0m | Métriques enregistrées : {'accuracy': 0.9649122807017544, 'f1_score': 0.9726027397260274, 'auc': 0.9957010582010581} | {}\n",
      "\u001b[32m2025-12-25 17:57:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mexperiment_tracking_service.py:61\u001b[0m | \u001b[33mclose()\u001b[0m | Fermeture de l'expérience. | {}\n",
      "\u001b[32m2025-12-25 17:57:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_tracker.py:76\u001b[0m | \u001b[33mend_run()\u001b[0m | Fermeture de la run : 72fde788a2db42efb00854294e6ed42d | {}\n",
      "\n",
      "Exécution terminée. Consulte MLflow UI.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0) Imports - Architecture (Clean)\n",
    "# ============================================================\n",
    "from health_lifestyle_diabetes.infrastructure.logger.config import configure_logging\n",
    "from health_lifestyle_diabetes.infrastructure.logger.loguru_logger import LoguruLogger\n",
    "from health_lifestyle_diabetes.infrastructure.tracking.mlflow_tracker import MLflowExperimentTracker\n",
    "from health_lifestyle_diabetes.application.services.experiment_tracking_service import ExperimentTrackingService\n",
    "from health_lifestyle_diabetes.infrastructure.tracking.run_name_generator import generate_run_name\n",
    "\n",
    "# ============================================================\n",
    "# 1) Imports - Dataset & XGBoost\n",
    "# ============================================================\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ============================================================\n",
    "# 2) Dataset réel\n",
    "# ============================================================\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 3) Logging global + dépendances\n",
    "# ============================================================\n",
    "configure_logging(env=\"dev\")\n",
    "\n",
    "logger = LoguruLogger()\n",
    "tracker = MLflowExperimentTracker(logger=logger)\n",
    "tracking = ExperimentTrackingService(tracker=tracker, logger=logger)\n",
    "\n",
    "# ============================================================\n",
    "# 4) Démarrage expérience MLflow\n",
    "# ============================================================\n",
    "EXPERIMENT_NAME = \"health_lifestyle_diabetes\"\n",
    "RUN_NAME = generate_run_name(prefix=\"XGB\")\n",
    "print(f\"Starting experiment '{EXPERIMENT_NAME}' with run name '{MODEL_NAME}'\")\n",
    "\n",
    "\n",
    "tracking.start_experiment(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    run_name=RUN_NAME\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 5) Modèle XGBoost + paramètres\n",
    "# ============================================================\n",
    "model_params = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"max_depth\": 6,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"subsample\": 0.8,\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    #\"use_label_encoder\": False\n",
    "}\n",
    "\n",
    "model = XGBClassifier(**model_params)\n",
    "\n",
    "# Log contexte d'entraînement dans MLflow\n",
    "tracking.log_training_context(\n",
    "    model_name=\"XGBClassifier\",\n",
    "    params=model_params\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 6) Entraînement réel\n",
    "# ============================================================\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ============================================================\n",
    "# 7) Évaluation\n",
    "# ============================================================\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"f1_score\": f1_score(y_test, y_pred),\n",
    "    \"auc\": roc_auc_score(y_test, y_proba)\n",
    "}\n",
    "\n",
    "tracking.log_evaluation(metrics)\n",
    "\n",
    "# ============================================================\n",
    "# 8) Artefact : sauvegarde du modèle\n",
    "# ============================================================\n",
    "#model_path = f\"models/{RUN_NAME}.json\"\n",
    "#model.save_model(model_path)\n",
    "#tracking.log_artifact(model_path)\n",
    "\n",
    "# ============================================================\n",
    "# 9) Fin de l'expérience\n",
    "# ============================================================\n",
    "tracking.close()\n",
    "\n",
    "print(\"\\nExécution terminée. Consulte MLflow UI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5e8386",
   "metadata": {},
   "source": [
    "# LightGBM + MLflow (Clean Architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16773d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-25 17:57:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mconfig.py:67\u001b[0m | \u001b[33mconfigure_logging()\u001b[0m | Loguru configuré avec succès (mode: dev) | {'env': 'dev'}\n",
      "\u001b[32m2025-12-25 17:57:54\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmlflow_setup.py:36\u001b[0m | \u001b[33m__init__()\u001b[0m | Tracking URI : sqlite://///Users/surelmanda/Downloads/ml-projects/mlflow_central/db/mlruns.db | {}\n",
      "\u001b[32m2025-12-25 17:57:54\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmlflow_setup.py:37\u001b[0m | \u001b[33m__init__()\u001b[0m | Artifact URI : /Users/surelmanda/Downloads/ml-projects/mlflow_central/mlflow_artifacts | {}\n",
      "\u001b[32m2025-12-25 17:57:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_setup.py:53\u001b[0m | \u001b[33mconfigure()\u001b[0m | MLflow configuré avec succès. | {}\n",
      "\u001b[32m2025-12-25 17:57:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_tracker.py:25\u001b[0m | \u001b[33m__init__()\u001b[0m | MLflowExperimentTracker prêt. | {}\n",
      "\u001b[32m2025-12-25 17:57:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mexperiment_tracking_service.py:23\u001b[0m | \u001b[33m__init__()\u001b[0m | ExperimentTrackingService initialisé. | {}\n",
      "\u001b[32m2025-12-25 17:57:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mexperiment_tracking_service.py:30\u001b[0m | \u001b[33mstart_experiment()\u001b[0m | Initialisation de l'expérience 'health_lifestyle_diabetes' (run='LGBM_2025-12-25_17h57m54s') | {}\n",
      "\u001b[32m2025-12-25 17:57:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_tracker.py:56\u001b[0m | \u001b[33msetup_experiment()\u001b[0m | Expérience active : health_lifestyle_diabetes | {}\n",
      "\u001b[32m2025-12-25 17:57:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_tracker.py:70\u001b[0m | \u001b[33mstart_run()\u001b[0m | Run démarrée : LGBM_2025-12-25_17h57m54s | {}\n",
      "\u001b[32m2025-12-25 17:57:54\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mexperiment_tracking_service.py:43\u001b[0m | \u001b[33mlog_training_context()\u001b[0m | Enregistrement du contexte d'entraînement pour LGBMClassifier | {}\n",
      "\u001b[32m2025-12-25 17:57:54\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmlflow_tracker.py:83\u001b[0m | \u001b[33mlog_params()\u001b[0m | Paramètres enregistrés : {'model': 'LGBMClassifier', 'n_estimators': 300, 'learning_rate': 0.05, 'num_leaves': 31, 'objective': 'binary'} | {}\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 285, number of negative: 170\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4542\n",
      "[LightGBM] [Info] Number of data points in the train set: 455, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.626374 -> initscore=0.516691\n",
      "[LightGBM] [Info] Start training from score 0.516691\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[32m2025-12-25 17:57:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mexperiment_tracking_service.py:48\u001b[0m | \u001b[33mlog_evaluation()\u001b[0m | Métriques d'évaluation : {'accuracy': 0.956140350877193, 'f1_score': 0.9659863945578231, 'auc': 0.9897486772486772} | {}\n",
      "\u001b[32m2025-12-25 17:57:55\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mmlflow_tracker.py:87\u001b[0m | \u001b[33mlog_metrics()\u001b[0m | Métriques enregistrées : {'accuracy': 0.956140350877193, 'f1_score': 0.9659863945578231, 'auc': 0.9897486772486772} | {}\n",
      "\u001b[32m2025-12-25 17:57:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mexperiment_tracking_service.py:61\u001b[0m | \u001b[33mclose()\u001b[0m | Fermeture de l'expérience. | {}\n",
      "\u001b[32m2025-12-25 17:57:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmlflow_tracker.py:76\u001b[0m | \u001b[33mend_run()\u001b[0m | Fermeture de la run : 658b271b12034562ae1b7109dde5ee7f | {}\n",
      "\n",
      "LightGBM - Exécution terminée. Consultez l'interface MLflow.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0) Imports - Architecture (Clean)\n",
    "# ============================================================\n",
    "from health_lifestyle_diabetes.infrastructure.logger.config import configure_logging\n",
    "from health_lifestyle_diabetes.infrastructure.logger.loguru_logger import LoguruLogger\n",
    "from health_lifestyle_diabetes.infrastructure.tracking.mlflow_tracker import MLflowExperimentTracker\n",
    "from health_lifestyle_diabetes.application.services.experiment_tracking_service import ExperimentTrackingService\n",
    "from health_lifestyle_diabetes.infrastructure.tracking.run_name_generator import generate_run_name\n",
    "\n",
    "# ============================================================\n",
    "# 1) Imports - Dataset & LightGBM\n",
    "# ============================================================\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# ============================================================\n",
    "# 2) Dataset réel\n",
    "# ============================================================\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 3) Logging global + dépendances\n",
    "# ============================================================\n",
    "configure_logging(env=\"dev\")\n",
    "\n",
    "logger = LoguruLogger()\n",
    "tracker = MLflowExperimentTracker(logger=logger)\n",
    "tracking = ExperimentTrackingService(tracker=tracker, logger=logger)\n",
    "\n",
    "# ============================================================\n",
    "# 4) Démarrage de l'expérience MLflow\n",
    "# ============================================================\n",
    "EXPERIMENT_NAME = \"health_lifestyle_diabetes\"\n",
    "RUN_NAME = generate_run_name(prefix=\"LGBM\")\n",
    "print(f\"Starting experiment '{EXPERIMENT_NAME}' with run name '{MODEL_NAME}'\")\n",
    "\n",
    "tracking.start_experiment(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    run_name=RUN_NAME\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 5) Définition du modèle LightGBM\n",
    "# ============================================================\n",
    "model_params = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"objective\": \"binary\"\n",
    "}\n",
    "\n",
    "model = LGBMClassifier(**model_params)\n",
    "\n",
    "# Log des paramètres dans MLflow\n",
    "tracking.log_training_context(\n",
    "    model_name=\"LGBMClassifier\",\n",
    "    params=model_params\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 6) Entraînement réel\n",
    "# ============================================================\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ============================================================\n",
    "# 7) Évaluation\n",
    "# ============================================================\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"f1_score\": f1_score(y_test, y_pred),\n",
    "    \"auc\": roc_auc_score(y_test, y_proba)\n",
    "}\n",
    "\n",
    "tracking.log_evaluation(metrics)\n",
    "\n",
    "# ============================================================\n",
    "# 8) Artefact : sauvegarde du modèle\n",
    "# ============================================================\n",
    "#model_path = f\"models/{RUN_NAME}.txt\"\n",
    "#model.booster_.save_model(model_path)  # Booster model save\n",
    "\n",
    "#tracking.log_artifact(model_path)\n",
    "\n",
    "# ============================================================\n",
    "# 9) Fin de l'expérience\n",
    "# ============================================================\n",
    "tracking.close()\n",
    "\n",
    "print(\"\\nLightGBM - Exécution terminée. Consultez l'interface MLflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deda8743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health-lifestyle-diabetes-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
